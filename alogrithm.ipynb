{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "\n",
    "file_path = 'pre/train.csv'\n",
    "\n",
    "# load dataset\n",
    "def load_data(path):\n",
    "    \n",
    "    # exclude the row of title \n",
    "    num = len(open(path,'r').readlines()) - 1\n",
    "    data = np.empty((num,4),dtype=\"uint32\")\n",
    "    label = np.empty((num,1),dtype=\"uint8\")\n",
    "    \n",
    "    #label,clickTime,conversionTime,creativeID,userID,positionID,connectionType,telecom,age,gender,residence\n",
    "    arr = genfromtxt(path, delimiter=',', dtype=\"uint32\", skip_header=1, usecols=(0,3,4,5,6,7))\n",
    "    \n",
    "    label = arr[:,0]\n",
    "    data = arr[:,1:]\n",
    "    \n",
    "    \n",
    "    return data,label\n",
    "\n",
    "X,Y = load_data(file_path)\n",
    "\n",
    "\n",
    "#preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "#print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "train_csv = np.genfromtxt('pre/train.csv', dtype=float, delimiter=',', names=True, usecols=[0,1,3,4,5,6,7])\n",
    "train_csv = np.sort(train_csv, order='clickTime')\n",
    "test_csv = np.genfromtxt('pre/test.csv', dtype=float, delimiter=',', names=True, usecols=[0,1,3,4,5,6,7])\n",
    "test_csv = np.sort(train_csv, order='clickTime')\n",
    "\n",
    "user_csv = np.genfromtxt('pre/user.csv', dtype=float, delimiter=',', names=True)\n",
    "\n",
    "t1 = pd.DataFrame(train_csv)\n",
    "t2 = pd.DataFrame(user_csv)\n",
    "t3 = pd.DataFrame(test_csv)\n",
    "\n",
    "trainData = t1.merge(t2)\n",
    "testData = t3.merge(t2)\n",
    "\n",
    "#np.savetxt('train.txt',trainData)\n",
    "#np.savetxt('test.txt',testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = trainData.as_matrix()\n",
    "X = tmp[:, [x for x  in (1,2,3,4,5)]].astype(np.uint32)\n",
    "Y = tmp[:, 0].astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huyssen/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype uint32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_minmax = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3374575, 5)\n",
      "(374953, 5)\n"
     ]
    }
   ],
   "source": [
    "train_split = 0.9\n",
    "\n",
    "train_size = int(X_minmax.shape[0]*train_split)\n",
    "test_size = X_minmax.shape[0] - train_size\n",
    "\n",
    "X_train, X_test = X_minmax[0:train_size,:], X_minmax[train_size:,:]\n",
    "y_train, y_test = Y[0:train_size], Y[train_size:,]\n",
    "\n",
    "#clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "#max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "\n",
    "#clf.score(X_test, y_test) \n",
    "#y_pred = clf.predict(X_test)\n",
    "index_train = np.where(y_train > 0)\n",
    "index_test = np.where(y_test > 0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huyssen/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.461862\teval-logloss:0.462917\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain-logloss:0.33549\teval-logloss:0.337156\n",
      "[2]\ttrain-logloss:0.257648\teval-logloss:0.257952\n",
      "[3]\ttrain-logloss:0.207313\teval-logloss:0.208437\n",
      "[4]\ttrain-logloss:0.173762\teval-logloss:0.1736\n",
      "[5]\ttrain-logloss:0.151383\teval-logloss:0.15224\n",
      "[6]\ttrain-logloss:0.136356\teval-logloss:0.137376\n",
      "[7]\ttrain-logloss:0.12634\teval-logloss:0.127617\n",
      "[8]\ttrain-logloss:0.119593\teval-logloss:0.121825\n",
      "[9]\ttrain-logloss:0.11516\teval-logloss:0.117898\n",
      "[10]\ttrain-logloss:0.112391\teval-logloss:0.114741\n",
      "[11]\ttrain-logloss:0.110588\teval-logloss:0.113337\n",
      "[12]\ttrain-logloss:0.109385\teval-logloss:0.112771\n",
      "[13]\ttrain-logloss:0.108618\teval-logloss:0.112676\n",
      "[14]\ttrain-logloss:0.107982\teval-logloss:0.112658\n",
      "[15]\ttrain-logloss:0.107295\teval-logloss:0.112473\n",
      "[16]\ttrain-logloss:0.106865\teval-logloss:0.112242\n",
      "[17]\ttrain-logloss:0.106636\teval-logloss:0.112755\n",
      "[18]\ttrain-logloss:0.106037\teval-logloss:0.112211\n",
      "[19]\ttrain-logloss:0.105698\teval-logloss:0.112012\n",
      "[20]\ttrain-logloss:0.105562\teval-logloss:0.11203\n",
      "[21]\ttrain-logloss:0.105405\teval-logloss:0.112204\n",
      "[22]\ttrain-logloss:0.105328\teval-logloss:0.112201\n",
      "[23]\ttrain-logloss:0.105187\teval-logloss:0.112147\n",
      "[24]\ttrain-logloss:0.105017\teval-logloss:0.11208\n",
      "[25]\ttrain-logloss:0.104902\teval-logloss:0.112078\n",
      "[26]\ttrain-logloss:0.104824\teval-logloss:0.112084\n",
      "[27]\ttrain-logloss:0.104637\teval-logloss:0.111937\n",
      "[28]\ttrain-logloss:0.104604\teval-logloss:0.111924\n",
      "[29]\ttrain-logloss:0.104365\teval-logloss:0.11188\n",
      "[30]\ttrain-logloss:0.104102\teval-logloss:0.111646\n",
      "[31]\ttrain-logloss:0.104044\teval-logloss:0.111654\n",
      "[32]\ttrain-logloss:0.103916\teval-logloss:0.111452\n",
      "[33]\ttrain-logloss:0.103803\teval-logloss:0.111346\n",
      "[34]\ttrain-logloss:0.103768\teval-logloss:0.111345\n",
      "[35]\ttrain-logloss:0.103644\teval-logloss:0.111238\n",
      "[36]\ttrain-logloss:0.103503\teval-logloss:0.111106\n",
      "[37]\ttrain-logloss:0.103438\teval-logloss:0.111073\n",
      "[38]\ttrain-logloss:0.10332\teval-logloss:0.110984\n",
      "[39]\ttrain-logloss:0.103206\teval-logloss:0.110857\n",
      "[40]\ttrain-logloss:0.103142\teval-logloss:0.110834\n",
      "[41]\ttrain-logloss:0.103104\teval-logloss:0.11082\n",
      "[42]\ttrain-logloss:0.103077\teval-logloss:0.110818\n",
      "[43]\ttrain-logloss:0.103019\teval-logloss:0.110742\n",
      "[44]\ttrain-logloss:0.102958\teval-logloss:0.110798\n",
      "[45]\ttrain-logloss:0.102898\teval-logloss:0.110736\n",
      "[46]\ttrain-logloss:0.102875\teval-logloss:0.110739\n",
      "[47]\ttrain-logloss:0.102838\teval-logloss:0.110752\n",
      "[48]\ttrain-logloss:0.102803\teval-logloss:0.110736\n",
      "[49]\ttrain-logloss:0.102753\teval-logloss:0.110531\n",
      "[50]\ttrain-logloss:0.102702\teval-logloss:0.110486\n",
      "[51]\ttrain-logloss:0.102615\teval-logloss:0.110351\n",
      "[52]\ttrain-logloss:0.102553\teval-logloss:0.11031\n",
      "[53]\ttrain-logloss:0.102547\teval-logloss:0.110347\n",
      "[54]\ttrain-logloss:0.102493\teval-logloss:0.110303\n",
      "[55]\ttrain-logloss:0.102446\teval-logloss:0.110316\n",
      "[56]\ttrain-logloss:0.102349\teval-logloss:0.110287\n",
      "[57]\ttrain-logloss:0.102311\teval-logloss:0.110237\n",
      "[58]\ttrain-logloss:0.102307\teval-logloss:0.110305\n",
      "[59]\ttrain-logloss:0.102272\teval-logloss:0.110224\n",
      "[60]\ttrain-logloss:0.102228\teval-logloss:0.110119\n",
      "[61]\ttrain-logloss:0.102195\teval-logloss:0.110068\n",
      "[62]\ttrain-logloss:0.102146\teval-logloss:0.110082\n",
      "[63]\ttrain-logloss:0.102107\teval-logloss:0.110082\n",
      "[64]\ttrain-logloss:0.102053\teval-logloss:0.11004\n",
      "[65]\ttrain-logloss:0.102023\teval-logloss:0.110042\n",
      "[66]\ttrain-logloss:0.101975\teval-logloss:0.110005\n",
      "[67]\ttrain-logloss:0.10196\teval-logloss:0.110006\n",
      "[68]\ttrain-logloss:0.101953\teval-logloss:0.110029\n",
      "[69]\ttrain-logloss:0.101945\teval-logloss:0.110027\n",
      "[70]\ttrain-logloss:0.101891\teval-logloss:0.11001\n",
      "[71]\ttrain-logloss:0.101855\teval-logloss:0.110039\n",
      "[72]\ttrain-logloss:0.10183\teval-logloss:0.110049\n",
      "[73]\ttrain-logloss:0.101781\teval-logloss:0.109998\n",
      "[74]\ttrain-logloss:0.101763\teval-logloss:0.110016\n",
      "[75]\ttrain-logloss:0.10173\teval-logloss:0.110004\n",
      "[76]\ttrain-logloss:0.1017\teval-logloss:0.110005\n",
      "[77]\ttrain-logloss:0.101667\teval-logloss:0.10998\n",
      "[78]\ttrain-logloss:0.101652\teval-logloss:0.109989\n",
      "[79]\ttrain-logloss:0.10163\teval-logloss:0.109956\n",
      "[80]\ttrain-logloss:0.101623\teval-logloss:0.109959\n",
      "[81]\ttrain-logloss:0.101613\teval-logloss:0.11006\n",
      "[82]\ttrain-logloss:0.101604\teval-logloss:0.110059\n",
      "[83]\ttrain-logloss:0.1016\teval-logloss:0.110061\n",
      "[84]\ttrain-logloss:0.101593\teval-logloss:0.110061\n",
      "[85]\ttrain-logloss:0.101561\teval-logloss:0.110004\n",
      "[86]\ttrain-logloss:0.101535\teval-logloss:0.109985\n",
      "[87]\ttrain-logloss:0.101517\teval-logloss:0.109994\n",
      "[88]\ttrain-logloss:0.10148\teval-logloss:0.109972\n",
      "[89]\ttrain-logloss:0.101465\teval-logloss:0.109968\n",
      "Stopping. Best iteration:\n",
      "[79]\ttrain-logloss:0.10163\teval-logloss:0.109956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "data_train, data_test = X_train, X_test\n",
    "label_trian, label_test = y_train, y_test\n",
    "\n",
    "#get data\n",
    "dtrain = xgb.DMatrix(data_train, label=label_trian, missing = -999.0)\n",
    "dtest = xgb.DMatrix(data_test, label=label_test, missing = -999.0)\n",
    "#set params\n",
    "params = {'bst:max_depth':2, 'bst:eta':1, 'silent':False, 'objective':'binary:logistic','nthread':6,'eval_metric':'logloss'}\n",
    "\n",
    "evallist  = [(dtrain,'train'),(dtest,'eval')]\n",
    "#train\n",
    "num_round = 300\n",
    "stopping_rounds = 15\n",
    "bst = xgb.train(params, dtrain, num_round, evallist, early_stopping_rounds=stopping_rounds)\n",
    "#15 step 0.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bst.save_model('size90_250_best.model') 0.085451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0055593   0.00099833  0.00926953 ...,  0.01527131  0.00622515\n",
      "  0.00470881]\n",
      "[0 0 0 ..., 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.085235244974789445"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#print(data_test.shape)\n",
    "y_pred = bst.predict(dtest)\n",
    "print(y_pred)\n",
    "print(label_test)\n",
    "metrics.log_loss(label_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load real dataset\n",
    "def load_pre_data(path):\n",
    "    \n",
    "    # exclude the row of title \n",
    "    num = len(open(path,'r').readlines()) - 1\n",
    "    data = np.empty((num,4),dtype=\"uint32\")\n",
    "    instance = np.empty((num,1),dtype=\"uint32\")\n",
    "    \n",
    "    arr = genfromtxt(path, delimiter=',', dtype=\"uint32\", skip_header=1, usecols=(0,3,4,6,7))\n",
    "    \n",
    "    instance = arr[:,0]\n",
    "    data = arr[:,1:]\n",
    "\n",
    "    return instance,data\n",
    "\n",
    "ins,realX = load_pre_data(\"pre/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dreal = xgb.DMatrix(realX, missing = -999.0)\n",
    "Y_real = bst.predict(dreal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = np.column_stack((ins,Y_real))\n",
    "np.savetxt(\"pred5.csv\", res,fmt='%.9f',delimiter=',',header=\" instanceID,prob\")\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "def MLP(dim):\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=dim, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = MLP(6)\n",
    "\n",
    "model.fit(X_train, y_train,epochs=20,batch_size=2500)\n",
    "\n",
    "#score = model.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "#plot_model(model, to_file='model.png')\n",
    "#SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
